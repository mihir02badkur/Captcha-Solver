{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvhmBiypRRPS"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D,MaxPool2D, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEK2XSzAdt2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da822b63-b013-409f-bc02-cbb97cbb6eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pFKKhBpTQUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4dd9c7-4943-41ab-bb3f-04ca961ee463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       0      1      2      3      4      5      6      7      8      9  ...  \\\n",
            "0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  ...   \n",
            "1  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  ...   \n",
            "2  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  ...   \n",
            "3  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  ...   \n",
            "4  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  ...   \n",
            "5  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  ...   \n",
            "6  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  ...   \n",
            "7  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  ...   \n",
            "8  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  ...   \n",
            "9  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  ...   \n",
            "\n",
            "     775    776    777    778    779    780    781    782    783  Label  \n",
            "0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   36.0  \n",
            "1  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   43.0  \n",
            "2  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   15.0  \n",
            "3  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   42.0  \n",
            "4  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   26.0  \n",
            "5  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   32.0  \n",
            "6  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   20.0  \n",
            "7  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   46.0  \n",
            "8  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   43.0  \n",
            "9  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   15.0  \n",
            "\n",
            "[10 rows x 785 columns]\n"
          ]
        }
      ],
      "source": [
        "# Reading the Dataset\n",
        "data = pd.read_csv(\"/content/drive/My Drive/Mosaic ps1 datasets/Dataset 3.csv\").astype('float32')\n",
        "print(data.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping characters\n",
        "drop_rows = [11, 12, 16, 18, 19, 20, 21, 22, 24, 26, 31, 32, 33, 34, 37, 40, 41, 44]\n",
        "data = data[data['Label'].isin(drop_rows) == False]\n",
        "data.index= range(len(data))"
      ],
      "metadata": {
        "id": "vMOZnij0rpBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Label'].value_counts()"
      ],
      "metadata": {
        "id": "ArftL93dstdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefcbf96-fbd5-4a64-c367-02b381add7d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0     2600\n",
              "7.0     2550\n",
              "6.0     2550\n",
              "4.0     2550\n",
              "2.0     2550\n",
              "3.0     2500\n",
              "1.0     2450\n",
              "43.0    2400\n",
              "27.0    2400\n",
              "10.0    2400\n",
              "39.0    2400\n",
              "38.0    2400\n",
              "36.0    2400\n",
              "23.0    2400\n",
              "28.0    2400\n",
              "35.0    2400\n",
              "25.0    2400\n",
              "29.0    2400\n",
              "14.0    2400\n",
              "17.0    2400\n",
              "13.0    2400\n",
              "46.0    2400\n",
              "42.0    2400\n",
              "15.0    2400\n",
              "30.0    2400\n",
              "45.0    2399\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dictionary for all characters left\n",
        "dic = {1: 0,2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6,10: 7,13: 8,14: 9,15: 10,17: 11,23: 12,25: 13,27: 14,28: 15,29: 16,30: 17, 35: 18,36: 19,38: 20,39: 21,42: 22,43: 23,45: 24,46: 25}\n",
        "data['Label']=data['Label'].map(dic)"
      ],
      "metadata": {
        "id": "wc5158HZ3cGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yfoiJX-Tv2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "3d5597f5-72d5-47b8-e08b-256eef2f2318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0      1      2      3      4      5      6      7      8      9  \\\n",
              "0      255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "1      255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "2      255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "3      255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "4      255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "63344  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "63345  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "63346  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "63347  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "63348  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "\n",
              "       ...    774    775    776    777    778    779    780    781    782  \\\n",
              "0      ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "1      ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "2      ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "3      ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "4      ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "63344  ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "63345  ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "63346  ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "63347  ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "63348  ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
              "\n",
              "         783  \n",
              "0      255.0  \n",
              "1      255.0  \n",
              "2      255.0  \n",
              "3      255.0  \n",
              "4      255.0  \n",
              "...      ...  \n",
              "63344  255.0  \n",
              "63345  255.0  \n",
              "63346  255.0  \n",
              "63347  255.0  \n",
              "63348  255.0  \n",
              "\n",
              "[63349 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce904b51-360f-4b36-bcee-76b3eea2f6f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63344</th>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63345</th>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63346</th>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63347</th>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63348</th>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63349 rows Ã— 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce904b51-360f-4b36-bcee-76b3eea2f6f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce904b51-360f-4b36-bcee-76b3eea2f6f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce904b51-360f-4b36-bcee-76b3eea2f6f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Stroing data and result in x and y respectively\n",
        "y = data['Label']\n",
        "X = data.drop('Label',axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzvTmmSUTyfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e7b3b9-faf2-4592-f7f4-8f90f1cf1741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape:  (63349, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "train_x = X\n",
        "train_y = y\n",
        "train_x = np.reshape(train_x.values, (train_x.shape[0], 28,28))\n",
        "print(\"Train data shape: \", train_x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l07ojXZFUWsf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "0d9f65fe-f240-40ff-b2e5-1affac64993a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting data\n",
        "shuff = shuffle(train_x[:])\n",
        "fig, ax = plt.subplots(3,3, figsize = (10,10))\n",
        "axes = ax.flatten()\n",
        "for i in range(9):\n",
        "    axes[i].imshow(np.reshape(shuff[i], (28,28)), cmap=\"Greys\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEsigjOWUZjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476c2d05-fd74-4f4e-d602-053a37ae8e1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of train data:  (63349, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "train_X = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
        "print(\"New shape of train data: \", train_X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86SLQ5UCfk-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d61941-8683-4b59-bc5f-8736fab2ff60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    19\n",
              "1    23\n",
              "2    10\n",
              "3    22\n",
              "4    25\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "train_y.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHfG3wvJUdO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a6461b-02cd-4357-8692-93aee57d2184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of train labels:  (63349, 26)\n"
          ]
        }
      ],
      "source": [
        "train_yOHE = to_categorical(train_y, num_classes = 26, dtype='int')\n",
        "print(\"New shape of train labels: \", train_yOHE.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model=Sequential()\n",
        "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(26, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "A69Ua8EiGXMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2ab15e-1f2e-43b0-aec1-b056c9ebcd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 26, 26, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 24, 24, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 12, 12, 32)        25632     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 12, 12, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 10, 10, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 10, 10, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 4, 4, 64)          102464    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 4, 4, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 1, 1, 128)         131200    \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 1, 1, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 26)                3354      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 329,306\n",
            "Trainable params: 328,474\n",
            "Non-trainable params: 832\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A_6CRvrUjVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01940ee6-ac5d-4ebb-fa49-70c3170279af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1980/1980 [==============================] - 31s 15ms/step - loss: 0.5044 - accuracy: 0.8610\n",
            "Epoch 2/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.1856 - accuracy: 0.9498\n",
            "Epoch 3/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.1517 - accuracy: 0.9592\n",
            "Epoch 4/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.1337 - accuracy: 0.9650\n",
            "Epoch 5/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.1193 - accuracy: 0.9685\n",
            "Epoch 6/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.1081 - accuracy: 0.9720\n",
            "Epoch 7/30\n",
            "1980/1980 [==============================] - 27s 13ms/step - loss: 0.1015 - accuracy: 0.9737\n",
            "Epoch 8/30\n",
            "1980/1980 [==============================] - 27s 13ms/step - loss: 0.0947 - accuracy: 0.9753\n",
            "Epoch 9/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0896 - accuracy: 0.9772\n",
            "Epoch 10/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0841 - accuracy: 0.9784\n",
            "Epoch 11/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0787 - accuracy: 0.9796\n",
            "Epoch 12/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0766 - accuracy: 0.9800\n",
            "Epoch 13/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0726 - accuracy: 0.9808\n",
            "Epoch 14/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0694 - accuracy: 0.9820\n",
            "Epoch 15/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0682 - accuracy: 0.9820\n",
            "Epoch 16/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0647 - accuracy: 0.9828\n",
            "Epoch 17/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0629 - accuracy: 0.9831\n",
            "Epoch 18/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0607 - accuracy: 0.9837\n",
            "Epoch 19/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0593 - accuracy: 0.9842\n",
            "Epoch 20/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0572 - accuracy: 0.9848\n",
            "Epoch 21/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0566 - accuracy: 0.9849\n",
            "Epoch 22/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0531 - accuracy: 0.9855\n",
            "Epoch 23/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0532 - accuracy: 0.9857\n",
            "Epoch 24/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0522 - accuracy: 0.9854\n",
            "Epoch 25/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0504 - accuracy: 0.9862\n",
            "Epoch 26/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0485 - accuracy: 0.9865\n",
            "Epoch 27/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0482 - accuracy: 0.9863\n",
            "Epoch 28/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0469 - accuracy: 0.9869\n",
            "Epoch 29/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0457 - accuracy: 0.9869\n",
            "Epoch 30/30\n",
            "1980/1980 [==============================] - 26s 13ms/step - loss: 0.0454 - accuracy: 0.9873\n"
          ]
        }
      ],
      "source": [
        "# Model Training\n",
        "history = model.fit(train_X, train_yOHE, epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRKWNXmgUnOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4dad82-5a59-45ba-e9c1-6fda737eeb85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 26, 26, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 24, 24, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 12, 12, 32)        25632     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 12, 12, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 10, 10, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 10, 10, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 4, 4, 64)          102464    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 4, 4, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 1, 1, 128)         131200    \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 1, 1, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 26)                3354      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 329,306\n",
            "Trainable params: 328,474\n",
            "Non-trainable params: 832\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Saving the Model\n",
        "model.summary() \n",
        "model.save(r'model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9PvM8yZUowu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54de1570-1a3a-4231-fe87-43c5a1769638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is : [0.8609922528266907, 0.9498176574707031, 0.9591943025588989, 0.9649560451507568, 0.9684604406356812, 0.971980631351471, 0.9737012386322021, 0.9753271341323853, 0.977189838886261, 0.9784053564071655, 0.9796366095542908, 0.9800154566764832, 0.9807889461517334, 0.9819570779800415, 0.981972873210907, 0.9827937483787537, 0.9831410050392151, 0.9837092757225037, 0.984151303768158, 0.9848458766937256, 0.9849405884742737, 0.9854772686958313, 0.9857140779495239, 0.9854456782341003, 0.9861876368522644, 0.9865348935127258, 0.9863454699516296, 0.9868980050086975, 0.9869137406349182, 0.9873083829879761]\n",
            "The training loss is : [0.504442036151886, 0.1856319159269333, 0.15167340636253357, 0.13365881145000458, 0.11930288374423981, 0.10806269198656082, 0.10153697431087494, 0.0947011262178421, 0.08961794525384903, 0.08414848893880844, 0.078708715736866, 0.07655134797096252, 0.07261747121810913, 0.0694127306342125, 0.06823378056287766, 0.06469455361366272, 0.06294742971658707, 0.06068377196788788, 0.05933045223355293, 0.05718185752630234, 0.056625328958034515, 0.05312526598572731, 0.053233880549669266, 0.052212584763765335, 0.050389207899570465, 0.04846840724349022, 0.04823700338602066, 0.04693185165524483, 0.0456705167889595, 0.04542597010731697]\n"
          ]
        }
      ],
      "source": [
        "# Printing Model accuracy\n",
        "print(\"The training accuracy is :\", history.history['accuracy'])\n",
        "print(\"The training loss is :\", history.history['loss'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Captcha Solver Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}